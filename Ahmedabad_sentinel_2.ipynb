{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMrw/x7bBl7SoISTh14XkKJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DhrumilPrajapati03/Segmentation_model_using_U-net/blob/main/Ahmedabad_sentinel_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing on Ahmedabad's sentinel-2 Dataset"
      ],
      "metadata": {
        "id": "kPHaKg8LqBGn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Installing libs\n"
      ],
      "metadata": {
        "id": "tzJww4IIp3FM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install patchify\n",
        "!pip install segmentation-models\n",
        "!pip install tensorflow"
      ],
      "metadata": {
        "id": "lQZEhuZkp0Gc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### converting from jp2 to tiff"
      ],
      "metadata": {
        "id": "KTR7sRs3pnIy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import rasterio\n",
        "from rasterio.shutil import copy as rio_copy\n",
        "\n",
        "input_folder = \"/content/drive/MyDrive/S2A_MSIL1C_20151120T054122_N0500_R005_T43QBF_20231008T183202.SAFE/S2B_MSIL1C_20201128T054159_N0500_R005_T43QBF_20230409T052646.SAFE/S2B_MSIL1C_20201128T054159_N0500_R005_T43QBF_20230409T052646.SAFE/GRANULE/L1C_T43QBF_A019479_20201128T054158/IMG_DATA\"  # The folder with .jp2 files\n",
        "output_folder = \"/content/drive/MyDrive/S2A_MSIL1C_20151120T054122_N0500_R005_T43QBF_20231008T183202.SAFE/S2B_MSIL1C_20201128T054159_N0500_R005_T43QBF_20230409T052646.SAFE/S2B_MSIL1C_20201128T054159_N0500_R005_T43QBF_20230409T052646.SAFE/GRANULE/L1C_T43QBF_A019479_20201128T054158/tiff files02\"\n",
        "\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "for filename in os.listdir(input_folder):\n",
        "    if filename.endswith(\".jp2\"):\n",
        "        input_path = os.path.join(input_folder, filename)\n",
        "        output_path = os.path.join(output_folder, filename.replace(\".jp2\", \".tif\"))\n",
        "\n",
        "        with rasterio.open(input_path) as src:\n",
        "            rio_copy(src, output_path, driver='GTiff')\n",
        "            print(f\"Converted {filename} to .tif\")"
      ],
      "metadata": {
        "id": "p-6hmxf9pmUg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Checking Dimensions of both images"
      ],
      "metadata": {
        "id": "SMX-k0yRnbSF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y6MOMCBemOfe"
      },
      "outputs": [],
      "source": [
        "# prompt: give me script to find the dimensions of the two tif images\n",
        "import rasterio\n",
        "# Paths to your two input images\n",
        "image1_path = '/content/drive/MyDrive/Ahmedabad_sentinel_dataset/2015/amd_2015.tif'\n",
        "image2_path = '/content/drive/MyDrive/Ahmedabad_sentinel_dataset/2020/amd_2020.tif'\n",
        "\n",
        "with rasterio.open(image1_path) as src1:\n",
        "    print(f\"Image 1 dimensions: {src1.width} x {src1.height}\")\n",
        "\n",
        "with rasterio.open(image2_path) as src2:\n",
        "    print(f\"Image 2 dimensions: {src2.width} x {src2.height}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### patchifying both images and save in png format"
      ],
      "metadata": {
        "id": "meiG37t1njWZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: give me code to do 64x64 patches of both images and sav in png form\n",
        "\n",
        "from patchify import patchify\n",
        "\n",
        "def create_patches(image_path, output_dir, patch_size=64):\n",
        "    \"\"\"Creates patches of a given size from an image and saves them as PNGs.\"\"\"\n",
        "    try:\n",
        "        with rasterio.open(image_path) as src:\n",
        "            image = src.read()\n",
        "            patches = patchify(image, (image.shape[0], patch_size, patch_size), step=patch_size)\n",
        "\n",
        "            # Iterate through patches\n",
        "            patch_index = 0\n",
        "            for i in range(patches.shape[0]):\n",
        "                for j in range(patches.shape[1]):\n",
        "                    for k in range(patches.shape[2]):\n",
        "                        patch = patches[i, j, k, :, :]\n",
        "                        patch_filename = os.path.join(output_dir, f'patch_{patch_index:04d}.png')\n",
        "\n",
        "                        # Convert to PIL image and save\n",
        "                        patch_image = Image.fromarray(patch.astype(np.uint8))\n",
        "                        patch_image.save(patch_filename)\n",
        "\n",
        "                        patch_index += 1\n",
        "\n",
        "            print(f\"✅ Patches created and saved in {output_dir}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ Error processing {image_path}: {str(e)}\")\n",
        "\n",
        "\n",
        "# Example usage for image1 and image2\n",
        "image1_path = '/content/drive/MyDrive/Ahmedabad_sentinel_dataset/2015/amd_2015.tif'\n",
        "image2_path = '/content/drive/MyDrive/Ahmedabad_sentinel_dataset/2020/amd_2020.tif'\n",
        "\n",
        "output_dir_image1 = '/content/drive/MyDrive/image1_patches'\n",
        "output_dir_image2 = '/content/drive/MyDrive/image2_patches'\n",
        "\n",
        "os.makedirs(output_dir_image1, exist_ok=True)\n",
        "os.makedirs(output_dir_image2, exist_ok=True)\n",
        "\n",
        "create_patches(image1_path, output_dir_image1)\n",
        "create_patches(image2_path, output_dir_image2)\n"
      ],
      "metadata": {
        "id": "-PoL-AHLmTXC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Counting total number of patches"
      ],
      "metadata": {
        "id": "HcuE0d-EnvIm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def count_patches(folder_path):\n",
        "  \"\"\"Counts the number of patches in a given folder.\"\"\"\n",
        "  patch_count = 0\n",
        "  for filename in os.listdir(folder_path):\n",
        "    if filename.endswith(('.tif', '.png')):  # Adjust file extensions if needed\n",
        "      patch_count += 1\n",
        "  return patch_count\n",
        "\n",
        "# Example usage:\n",
        "folder1 = '/content/drive/MyDrive/Ahmedabad_sentinel_dataset/patches_2015'\n",
        "folder2 = '/content/drive/MyDrive/Ahmedabad_sentinel_dataset/patches_2020'\n",
        "\n",
        "\n",
        "total_patches = count_patches(folder1) + count_patches(folder2)\n",
        "print(f\"Total number of patches in both folders: {total_patches}\")\n"
      ],
      "metadata": {
        "id": "-SOioWqqmZ4R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### plot first 5 patches"
      ],
      "metadata": {
        "id": "pen_14EVn0xO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "# Define the folder paths\n",
        "folder_2015 = '/content/drive/MyDrive/Ahmedabad_sentinel_dataset/patches_2015'\n",
        "folder_2020 = '/content/drive/MyDrive/Ahmedabad_sentinel_dataset/patches_2020'\n",
        "\n",
        "# Function to load images from a folder and return the first n images\n",
        "def load_images(folder_path, num_images=5):\n",
        "    images = []\n",
        "    for i, filename in enumerate(os.listdir(folder_path)):\n",
        "        if filename.endswith(('.png', '.jpg', '.jpeg')):  # Modify the extensions as per your image formats\n",
        "            image_path = os.path.join(folder_path, filename)\n",
        "            image = Image.open(image_path)\n",
        "            images.append(image)\n",
        "        if len(images) == num_images:\n",
        "            break\n",
        "    return images\n",
        "\n",
        "# Load the first 5 patches from both folders\n",
        "patches_2015 = load_images(folder_2015, num_images=5)\n",
        "patches_2020 = load_images(folder_2020, num_images=5)\n",
        "\n",
        "# Plot the images\n",
        "fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
        "\n",
        "# Plot 2015 patches\n",
        "for i, ax in enumerate(axes[0]):\n",
        "    ax.imshow(patches_2015[i])\n",
        "    ax.axis('off')  # Hide axes\n",
        "    ax.set_title(f'Patch {i+1} (2015)')\n",
        "\n",
        "# Plot 2020 patches\n",
        "for i, ax in enumerate(axes[1]):\n",
        "    ax.imshow(patches_2020[i])\n",
        "    ax.axis('off')  # Hide axes\n",
        "    ax.set_title(f'Patch {i+1} (2020)')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "glFWv-aLmeg6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Plotting Before-after and predicted mask"
      ],
      "metadata": {
        "id": "9FW9nujTn6XW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "from skimage import io\n",
        "import segmentation_models as sm\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ... (previous code for loading model and preprocessing) ...\n",
        "# prompt: instead of test_triples i want to predict my images seperately, means i'll give two tif images and it should give predicted output\n",
        "\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from skimage import io\n",
        "import segmentation_models as sm\n",
        "from tensorflow import keras\n",
        "\n",
        "# --- Load model ---\n",
        "model_path = '/content/drive/MyDrive/U_NET Segmentation_model/model.keras'\n",
        "from segmentation_models import Unet\n",
        "model = Unet(backbone_name='resnet34', encoder_weights='imagenet', decoder_block_type='upsampling')\n",
        "# Compile the model with the desired loss function\n",
        "def custom_loss(y_true, y_pred):\n",
        "    bce = keras.losses.BinaryCrossentropy()\n",
        "    jaccard = sm.losses.JaccardLoss()\n",
        "    return bce(y_true, y_pred) + jaccard(y_true, y_pred)\n",
        "model.compile(optimizer='adam', loss=custom_loss, metrics=['accuracy'])\n",
        "# Load the weights from the saved model file\n",
        "model.load_weights(model_path)\n",
        "# model = tf.keras.models.load_model(model_path)\n",
        "print(\"✅ Model Loaded\")\n",
        "\n",
        "BACKBONE = 'resnet34'\n",
        "preprocess_input = sm.get_preprocessing(BACKBONE)\n",
        "\n",
        "def preprocess_image(image_path):\n",
        "    img = Image.open(image_path)\n",
        "    img = np.array(img) / 255\n",
        "    img = img.astype(np.float32)\n",
        "    img = preprocess_input(img)\n",
        "    return img\n",
        "\n",
        "def predict_image_pair(image1_path, image2_path):\n",
        "    # Preprocess images\n",
        "    im1 = preprocess_image(image1_path)\n",
        "    im2 = preprocess_image(image2_path)\n",
        "\n",
        "    # Calculate the difference\n",
        "    x = im1 - im2\n",
        "\n",
        "    # Expand dimensions for model input\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "\n",
        "    # Make prediction\n",
        "    y_pred = model.predict(x)\n",
        "    y_pred = y_pred[0]\n",
        "\n",
        "    return y_pred\n",
        "\n",
        "\n",
        "# Example usage\n",
        "image1_path = \"/content/drive/MyDrive/Ahmedabad_sentinel_dataset/patches_2015/patch_0_192.png\"  # Replace with the actual path\n",
        "image2_path = \"/content/drive/MyDrive/Ahmedabad_sentinel_dataset/patches_2020/patch_0_192.png\"  # Replace with the actual path\n",
        "\n",
        "prediction = predict_image_pair(image1_path, image2_path)\n",
        "\n",
        "# --- Display images ---\n",
        "image1 = Image.open(image1_path)\n",
        "image2 = Image.open(image2_path)\n",
        "\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "axes[0].imshow(image1)\n",
        "axes[0].set_title(\"Image 1\")\n",
        "\n",
        "axes[1].imshow(image2)\n",
        "axes[1].set_title(\"Image 2\")\n",
        "\n",
        "axes[2].imshow(prediction[:, :, 0], cmap='gray')  # Assuming prediction is in (H, W, C) format\n",
        "axes[2].set_title(\"Predicted Change Mask\")\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "AQE0iffAminB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Plotting first 10 patches from both folder along with their predicted mask\n"
      ],
      "metadata": {
        "id": "gh9NLrDloE_D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage import io\n",
        "import segmentation_models as sm\n",
        "from tensorflow import keras\n",
        "\n",
        "# --- Load model ---\n",
        "model_path = '/content/drive/MyDrive/U_NET Segmentation_model/model.keras'\n",
        "from segmentation_models import Unet\n",
        "model = Unet(backbone_name='resnet34', encoder_weights='imagenet', decoder_block_type='upsampling')\n",
        "\n",
        "# Compile the model with the desired loss function\n",
        "def custom_loss(y_true, y_pred):\n",
        "    bce = keras.losses.BinaryCrossentropy()\n",
        "    jaccard = sm.losses.JaccardLoss()\n",
        "    return bce(y_true, y_pred) + jaccard(y_true, y_pred)\n",
        "\n",
        "model.compile(optimizer='adam', loss=custom_loss, metrics=['accuracy'])\n",
        "\n",
        "# Load the weights from the saved model file\n",
        "model.load_weights(model_path)\n",
        "print(\"✅ Model Loaded\")\n",
        "\n",
        "BACKBONE = 'resnet34'\n",
        "preprocess_input = sm.get_preprocessing(BACKBONE)\n",
        "\n",
        "# Preprocessing function\n",
        "def preprocess_image(image_path):\n",
        "    img = Image.open(image_path)\n",
        "    img = np.array(img) / 255\n",
        "    img = img.astype(np.float32)\n",
        "    img = preprocess_input(img)\n",
        "    return img\n",
        "\n",
        "# Prediction function for a pair of images\n",
        "def predict_image_pair(image1_path, image2_path):\n",
        "    # Preprocess images\n",
        "    im1 = preprocess_image(image1_path)\n",
        "    im2 = preprocess_image(image2_path)\n",
        "\n",
        "    # Calculate the difference\n",
        "    x = im1 - im2\n",
        "\n",
        "    # Expand dimensions for model input\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "\n",
        "    # Make prediction\n",
        "    y_pred = model.predict(x)\n",
        "    y_pred = y_pred[0]\n",
        "\n",
        "    return y_pred\n",
        "\n",
        "# Paths to the folders containing patches\n",
        "folder_2015 = '/content/drive/MyDrive/Ahmedabad_sentinel_dataset/patches_2015/'\n",
        "folder_2020 = '/content/drive/MyDrive/Ahmedabad_sentinel_dataset/patches_2020/'\n",
        "\n",
        "# Function to load first n patches from the folders\n",
        "def load_patches(folder_path, num_patches=10):\n",
        "    patches = []\n",
        "    for i, filename in enumerate(sorted(os.listdir(folder_path))[:num_patches]):\n",
        "        if filename.endswith(('.png', '.jpg', '.jpeg')):\n",
        "            image_path = os.path.join(folder_path, filename)\n",
        "            patches.append(image_path)\n",
        "    return patches\n",
        "\n",
        "# Load the first 10 patches from both folders\n",
        "patches_2015 = load_patches(folder_2015, num_patches=10)\n",
        "patches_2020 = load_patches(folder_2020, num_patches=10)\n",
        "\n",
        "# --- Plotting the patches with predicted masks ---\n",
        "fig, axes = plt.subplots(10, 3, figsize=(15, 50))  # Adjusted for 10 rows\n",
        "\n",
        "for i in range(10):\n",
        "    image1_path = patches_2015[i]\n",
        "    image2_path = patches_2020[i]\n",
        "\n",
        "    # Get prediction for this pair of patches\n",
        "    prediction = predict_image_pair(image1_path, image2_path)\n",
        "\n",
        "    # Load original images\n",
        "    image1 = Image.open(image1_path)\n",
        "    image2 = Image.open(image2_path)\n",
        "\n",
        "    # Display the images and predicted mask\n",
        "    axes[i, 0].imshow(image1)\n",
        "    axes[i, 0].set_title(f\"Image 1 - Patch {i+1}\")\n",
        "    axes[i, 0].axis('off')\n",
        "\n",
        "    axes[i, 1].imshow(image2)\n",
        "    axes[i, 1].set_title(f\"Image 2 - Patch {i+1}\")\n",
        "    axes[i, 1].axis('off')\n",
        "\n",
        "    axes[i, 2].imshow(prediction[:, :, 0], cmap='gray')  # Assuming prediction is in (H, W, C) format\n",
        "    axes[i, 2].set_title(f\"Predicted Mask - Patch {i+1}\")\n",
        "    axes[i, 2].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "332diVKDmj2t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Plotting first 20 patches and predicted masks"
      ],
      "metadata": {
        "id": "rvJOpTAioSUb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage import io\n",
        "import segmentation_models as sm\n",
        "from tensorflow import keras\n",
        "\n",
        "# --- Load model ---\n",
        "model_path = '/content/drive/MyDrive/U_NET Segmentation_model/model.keras'\n",
        "from segmentation_models import Unet\n",
        "model = Unet(backbone_name='resnet34', encoder_weights='imagenet', decoder_block_type='upsampling')\n",
        "\n",
        "# Compile the model with the desired loss function\n",
        "def custom_loss(y_true, y_pred):\n",
        "    bce = keras.losses.BinaryCrossentropy()\n",
        "    jaccard = sm.losses.JaccardLoss()\n",
        "    return bce(y_true, y_pred) + jaccard(y_true, y_pred)\n",
        "\n",
        "model.compile(optimizer='adam', loss=custom_loss, metrics=['accuracy'])\n",
        "\n",
        "# Load the weights from the saved model file\n",
        "model.load_weights(model_path)\n",
        "print(\"✅ Model Loaded\")\n",
        "\n",
        "BACKBONE = 'resnet34'\n",
        "preprocess_input = sm.get_preprocessing(BACKBONE)\n",
        "\n",
        "# Preprocessing function\n",
        "def preprocess_image(image_path):\n",
        "    img = Image.open(image_path)\n",
        "    img = np.array(img) / 255\n",
        "    img = img.astype(np.float32)\n",
        "    img = preprocess_input(img)\n",
        "    return img\n",
        "\n",
        "# Prediction function for a pair of images\n",
        "def predict_image_pair(image1_path, image2_path):\n",
        "    # Preprocess images\n",
        "    im1 = preprocess_image(image1_path)\n",
        "    im2 = preprocess_image(image2_path)\n",
        "\n",
        "    # Calculate the difference\n",
        "    x = im1 - im2\n",
        "\n",
        "    # Expand dimensions for model input\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "\n",
        "    # Make prediction\n",
        "    y_pred = model.predict(x)\n",
        "    y_pred = y_pred[0]\n",
        "\n",
        "    return y_pred\n",
        "\n",
        "# Paths to the folders containing patches\n",
        "folder_2015 = '/content/drive/MyDrive/Ahmedabad_sentinel_dataset/patches_2015/'\n",
        "folder_2020 = '/content/drive/MyDrive/Ahmedabad_sentinel_dataset/patches_2020/'\n",
        "\n",
        "# Function to load first n patches from the folders\n",
        "def load_patches(folder_path, num_patches=20):\n",
        "    patches = []\n",
        "    for i, filename in enumerate(sorted(os.listdir(folder_path))[:num_patches]):\n",
        "        if filename.endswith(('.png', '.jpg', '.jpeg')):\n",
        "            image_path = os.path.join(folder_path, filename)\n",
        "            patches.append(image_path)\n",
        "    return patches\n",
        "\n",
        "# Load the first 10 patches from both folders\n",
        "patches_2015 = load_patches(folder_2015, num_patches=20)\n",
        "patches_2020 = load_patches(folder_2020, num_patches=20)\n",
        "\n",
        "# --- Plotting the patches with predicted masks ---\n",
        "fig, axes = plt.subplots(20, 3, figsize=(15, 50))  # Adjusted for 10 rows\n",
        "\n",
        "for i in range(20):\n",
        "    image1_path = patches_2015[i]\n",
        "    image2_path = patches_2020[i]\n",
        "\n",
        "    # Get prediction for this pair of patches\n",
        "    prediction = predict_image_pair(image1_path, image2_path)\n",
        "\n",
        "    # Load original images\n",
        "    image1 = Image.open(image1_path)\n",
        "    image2 = Image.open(image2_path)\n",
        "\n",
        "    # Display the images and predicted mask\n",
        "    axes[i, 0].imshow(image1)\n",
        "    axes[i, 0].set_title(f\"Patch {i+1} - Image 1\")\n",
        "    axes[i, 0].axis('off')\n",
        "\n",
        "    axes[i, 1].imshow(image2)\n",
        "    axes[i, 1].set_title(f\"Patch {i+1} - Image 2\")\n",
        "    axes[i, 1].axis('off')\n",
        "\n",
        "    axes[i, 2].imshow(prediction[:, :, 0], cmap='gray')  # Assuming prediction is in (H, W, C) format\n",
        "    axes[i, 2].set_title(f\"Patch {i+1} - Predicted Mask\")\n",
        "    axes[i, 2].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xsF_lrAUmn5r"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}